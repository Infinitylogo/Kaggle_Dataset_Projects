{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AHK14107_02pokemon_dataset_file.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"z3QxF0OQHbYv","executionInfo":{"status":"aborted","timestamp":1617850787374,"user_tz":-330,"elapsed":2525,"user":{"displayName":"ritu raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggib2r6f5L4UZq6ICY_YzlRkuRiUv4hXQOgVoa1qg=s64","userId":"11678065533499251038"}}},"source":["import keras\n","from keras.layers import Dense,Dropout,BatchNormalization,MaxPooling2D,Conv2D,Input\n","from keras import Model\n","from keras.layers import Flatten\n","from keras.preprocessing.image import ImageDataGenerator\n","import os\n","import numpy as np \n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"elsx0OA6HhVM","executionInfo":{"status":"aborted","timestamp":1617850787378,"user_tz":-330,"elapsed":2521,"user":{"displayName":"ritu raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggib2r6f5L4UZq6ICY_YzlRkuRiUv4hXQOgVoa1qg=s64","userId":"11678065533499251038"}}},"source":["data_dir='/content/drive/MyDrive/PokemonData/' "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UN8X4K2iSO44","executionInfo":{"status":"aborted","timestamp":1617850787382,"user_tz":-330,"elapsed":2521,"user":{"displayName":"ritu raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggib2r6f5L4UZq6ICY_YzlRkuRiUv4hXQOgVoa1qg=s64","userId":"11678065533499251038"}}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1b_7Fk-9SSAW","executionInfo":{"status":"ok","timestamp":1617850811404,"user_tz":-330,"elapsed":1053,"user":{"displayName":"ritu raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggib2r6f5L4UZq6ICY_YzlRkuRiUv4hXQOgVoa1qg=s64","userId":"11678065533499251038"}}},"source":["train_gen=ImageDataGenerator(rescale=1/255,validation_split=0.2)"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"id":"DIunsDMxTScI","executionInfo":{"status":"ok","timestamp":1617850811846,"user_tz":-330,"elapsed":724,"user":{"displayName":"ritu raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggib2r6f5L4UZq6ICY_YzlRkuRiUv4hXQOgVoa1qg=s64","userId":"11678065533499251038"}}},"source":["img_width = 256\n","img_height = 256\n","batch_size = 25"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"oScjvdmRSXzn","executionInfo":{"status":"error","timestamp":1617850812696,"user_tz":-330,"elapsed":970,"user":{"displayName":"ritu raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggib2r6f5L4UZq6ICY_YzlRkuRiUv4hXQOgVoa1qg=s64","userId":"11678065533499251038"}},"outputId":"e9a834bf-7b1f-4dae-9dac-404f85ee4a2b"},"source":["\n","train_generator=train_gen.flow_from_directory(data_dir,target_size=(img_width,img_height),subset='training',batch_size=batch_size,class_mode='categorical')\n","val=train_gen.flow_from_directory(data_dir,target_size=(img_width,img_height),subset='validation',batch_size=batch_size)"],"execution_count":69,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-69-80e78938bb2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   def flow_from_dataframe(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/PokemonData/'"]}]},{"cell_type":"code","metadata":{"id":"-yRGW3NYY0g8","executionInfo":{"status":"ok","timestamp":1617850787361,"user_tz":-330,"elapsed":2532,"user":{"displayName":"ritu raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggib2r6f5L4UZq6ICY_YzlRkuRiUv4hXQOgVoa1qg=s64","userId":"11678065533499251038"}},"outputId":"7179f05a-0075-4533-f1b7-06797d35e92f","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":65,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2xOHyiFBUrGx","executionInfo":{"status":"error","timestamp":1617850787389,"user_tz":-330,"elapsed":2552,"user":{"displayName":"ritu raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggib2r6f5L4UZq6ICY_YzlRkuRiUv4hXQOgVoa1qg=s64","userId":"11678065533499251038"}},"outputId":"e5efa742-fac6-4e98-c41a-1690b3a7f08d","colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["image,labels=next(train_generator)"],"execution_count":66,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-66-3d1621947212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/PokemonData/Magmar/8b8ae467e8c941248988eefa0e81e49b.jpg'"]}]},{"cell_type":"code","metadata":{"id":"AEQIHVvZUuLj","executionInfo":{"status":"aborted","timestamp":1617850787366,"user_tz":-330,"elapsed":2525,"user":{"displayName":"ritu raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggib2r6f5L4UZq6ICY_YzlRkuRiUv4hXQOgVoa1qg=s64","userId":"11678065533499251038"}}},"source":["for i in range(0,10):\n","    plt.imshow(image[i])\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jWFjZF0AR3DC","executionInfo":{"status":"aborted","timestamp":1617850787371,"user_tz":-330,"elapsed":2526,"user":{"displayName":"ritu raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggib2r6f5L4UZq6ICY_YzlRkuRiUv4hXQOgVoa1qg=s64","userId":"11678065533499251038"}}},"source":["classes=os.listdir(data_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hd8Uxe7DHg_h"},"source":["#model\n","\n","img_shape=(256,256,3)\n","\n","\n","model = keras.Sequential(name='RGBimg_Classify_Net')\n","model.add(keras.layers.Conv2D(128,3,input_shape=(img_shape),activation='relu'))\n","model.add(keras.layers.MaxPool2D())\n","model.add(keras.layers.Conv2D(128,3,activation='relu'))\n","model.add(keras.layers.MaxPool2D())\n","model.add(keras.layers.Conv2D(128,3,strides=(2,2),activation='relu'))\n","model.add(keras.layers.MaxPool2D())\n","model.add(keras.layers.BatchNormalization())\n","model.add(keras.layers.Conv2D(64,3,strides=(2,2),activation='relu'))\n","model.add(keras.layers.MaxPool2D())\n","model.add(keras.layers.Flatten())\n","model.add(keras.layers.Dropout(0.2))\n","model.add(keras.layers.Dense(1024,activation='relu'))\n","model.add(keras.layers.Dense(512,activation='relu'))\n","model.add(keras.layers.Dense(len(classes),activation='softmax'))\n","\n","\n","model.summary()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aeEY3N3yHg5q"},"source":["model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","history= model.fit(\n","    train_generator,\n","    validation_data=val,\n","    steps_per_epoch=train_step_epoch,\n","    validation_steps=val_step_epoch,\n","    epochs = 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jySdF04dI0Ky"},"source":["fig = plt.figure(figsize = (17, 4))\n","    \n","plt.subplot(121)\n","plt.plot(history.history['accuracy'], label = 'acc')\n","plt.plot(history.history['val_accuracy'], label = 'val_acc')\n","plt.legend()\n","plt.grid()\n","plt.title(f'accuracy')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rZKpLlABI0IR"},"source":["fig = plt.figure(figsize = (17, 4))\n","plt.subplot(122)\n","plt.plot(history.history['loss'], label = 'loss')\n","plt.plot(history.history['val_loss'], label = 'val_loss')\n","plt.legend()\n","plt.grid()\n","plt.title(f'loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yBUtm4HHI0Fo"},"source":["model.load_weights('model.hdf5')\n","model.save('model1.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WjWqCW2oI0Cx"},"source":["from sklearn.metrics import classification_report, confusion_matrix\n","Y_pred = model.predict(val)\n","# Convert predictions classes to one hot vectors \n","Y_pred_classes = np.argmax(Y_pred,axis = 1) \n","# Convert validation observations to one hot vectors\n","Y_true = np.argmax(train_generator,axis = 1) \n","# compute the confusion matrix\n","confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n","# plot the confusion matrix\n","f,ax = plt.subplots(figsize=(8, 8))\n","sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n","plt.xlabel(\"Predicted Label\")\n","plt.ylabel(\"True Label\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vOOAn9qZI0AX"},"source":["from sklearn.metrics import classification_report\n","print(classification_report(Y_true, Y_pred_classes))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dpEJutK0KLOK"},"source":["categories=os.listdir(data_dir)\n","Y_pred = model.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sZChbw1EIz9o"},"source":["plt.figure(figsize=(9,9))\n","for i in range(9):\n","    plt.subplot(3,3,i+1)\n","    plt.imshow(X_test[i])\n","    plt.xlabel('Actual:---:'+categories[Y_true[i]]+'\\n'+'predicted:----'+categories[np.argmax(Y_pred_classes[i])])\n","    plt.xticks([])\n","plt.show()\n","print('\\t')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JRJxYqYoQFwl"},"source":[""],"execution_count":null,"outputs":[]}]}